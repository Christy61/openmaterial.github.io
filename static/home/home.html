<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>3D Shape Reconstruction</title>
    <style>
        html,
        body {
            margin-top: 10px;
            font-family: Arial, sans-serif;
            overflow: visible;
        }

        .section {
            width: 100%;
            height: fit-content;
            overflow: visible;
        }

        .section-title {
            font-size: 1.4em;
            margin-top: 15px;
            text-align: left;
            font-weight: bold;
        }

        .container-tex {
            width: 90%;
            margin: 10px auto;
            justify-content: center;
            text-align: left;
        }

        a {
            color: #1154a0;
            font-weight: normal;
            text-decoration: underline;
            line-height: 1.5;
        }

        pre {
            width: 85%;
            color: #555;
            margin: 8px auto;
            padding: 8px 10px;
            background: #eee;
            border: 1px solid #ddd;
            border-radius: 5px;
            overflow: auto;
            font-family: Consolas, "Courier New", monospace;
            font-size: 14px;
            line-height: 1.5;
        }

        a:visited {
            color: #1154a0;
        }

        a:hover {
            color: darkblue;
        }

        a:active {
            color: red;
        }

        p {
            width: 90%;
            margin: 10px auto;
            justify-content: center;
            text-align: left;
            line-height: 1.5;
        }
    </style>
</head>

<body>
    <section class="section">
        <p class="section-title">Introduction</p>
        <p>
            Accurately reconstructing objects with complex optical properties, such as metals and glass, remains a
            formidable challenge due to their unique specular and light-transmission characteristics. To facilitate
            the
            development of solutions to these challenges, we introduce the OpenMaterial dataset, comprising 1001
            objects made of 295 distinct materials—including conductors, dielectrics, plastics, and their roughened
            variants—
            and captured under 723 diverse lighting conditions.
        </p>
        <img src="../images/teaser.png"
            style="width:60%; margin-left:auto; margin-right:auto; margin-top:20px; margin-bottom:5px; display:block">
        <p class="section-title">Overview</p>
        <p>
            Our dataset contains 1001 object centered scenes. To eliminate scale bias, we standardize object sizes
            within a unit sphere. This lets us sample camera
            positions using a Fibonacci grid on the upper hemisphere, ensuring uniform distribution and non-overlapping
            coverage. We then splits these camera positions into distinct training (50) and testing (40) viewpoints.
            All high-resolution images (1600x1200 pixels), rendered using Mitsuba, along with
            associated data including <b>camera positions</b>, <b>depth</b>, <b>3D object models</b>, and <b>object
                masks</b>, are stored in the
            standard Blender format, with support for conversion to the COLMAP format, facilitating usability across the
            research community.
        </p>
        <p class="section-title">Data structure</p>
        <p>
            The data structure of each subset is as follows:
        <pre>
            ├── name_of_object/[lighing_condition_name]-[material_type]-[material_name]
            │   ├── train
            │   │   ├── images
            │   │   │   ├── 000000.png
            │   │   │   |-- ...
            │   │   └── mask
            │   │   │   ├── 000000.png
            │   │   │   |-- ...
            │   │   └── depth
            │   │       ├── 000000.png
            │   │       |-- ...
            │   ├── test
            │   │   ├── images
            │   │   │   ├── 000000.png
            │   │   │   |-- ...
            │   │   └── mask
            │   │   │   ├── 000000.png
            │   │   │   |-- ...
            │   │   └── depth
            │   │       ├── 000000.png
            │   │       |-- ...
            │   └── transformas_train.json
            │   └── transformas_test.json
        </pre>
        </p>
        <p class="section-title">Citation</p>
        <p>
            If you find our work useful in your research, please cite:
        <pre>
        @article{Dang24,
            title={OpenMaterial: A Comprehensive Dataset of Complex Materials for 3D Reconstruction},
            author={Zheng Dang and Jialu Huang and Fei Wang and Mathieu Salzmann},
            journal={arXiv preprint arXiv:2406.08894},
            year={2024}
        }</pre>
        </p>
        <p class="section-title">Contact</p>
        <p>
            <a href="mailto:zheng.dang@epfl.ch">zheng.dang@epfl.ch</a>
        </p>
    </section>
</body>

</html>