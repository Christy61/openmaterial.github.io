<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>3D Shape Reconstruction</title>
    <style>
        html,
        body {
            margin-top: 10px;
            font-family: Arial, sans-serif;
            overflow: visible;
        }

        .section {
            width: 100%;
            height: fit-content;
            overflow: visible;
        }

        .section-title {
            font-size: 1.4em;
            margin-top: 15px;
            text-align: left;
            font-weight: bold;
        }

        .section-subtitle {
            font-size: 1.1em;
            margin-top: 5px;
            text-align: left;
            font-weight: bold;
        }

        .container-tex {
            width: 90%;
            margin: 10px auto;
            justify-content: center;
            text-align: left;
        }

        a {
            color: #1154a0;
            font-weight: normal;
            text-decoration: underline;
            line-height: 1.5;
        }

        pre {
            width: 85%;
            color: #555;
            margin: 8px auto;
            padding: 8px 10px;
            background: #eee;
            border: 1px solid #ddd;
            border-radius: 5px;
            overflow: auto;
            font-family: Consolas, "Courier New", monospace;
            font-size: 14px;
            line-height: 1.5;
        }

        a:visited {
            color: #1154a0;
        }

        a:hover {
            color: darkblue;
        }

        a:active {
            color: red;
        }

        p {
            width: 90%;
            margin: 10px auto;
            justify-content: center;
            text-align: left;
            line-height: 1.5;
        }

        ul.update-log {
            width: 87%;
            margin: 5px auto 15px;
            padding-left: 1.2em;
        }

        ul.update-log li {
            margin-bottom: 0.5em;
        }
    </style>
</head>

<body>
    <section class="section">
        <p class="section-title">Introduction</p>
        <p>
            Accurately reconstructing objects with complex optical properties, such as metals and glass, remains a
            formidable challenge due to their unique specular and light-transmission characteristics. To facilitate
            the
            development of solutions to these challenges, we introduce the OpenMaterial dataset, comprising 1001
            objects made of 295 distinct materials—including conductors, dielectrics, plastics, and their roughened
            variants—
            and captured under 723 diverse lighting conditions.
        </p>
        <img src="../images/teaser.png"
            style="width:60%; margin-left:auto; margin-right:auto; margin-top:20px; margin-bottom:5px; display:block">
        <p class="section-title">Overview</p>
        <p>
            Our dataset contains 1001 object centered scenes. To eliminate scale bias, we standardize object sizes
            within a unit sphere. This lets us sample camera
            positions using a Fibonacci grid on the upper hemisphere, ensuring uniform distribution and non-overlapping
            coverage. We then splits these camera positions into distinct training (50) and testing (40) viewpoints.
            All high-resolution images (1600x1200 pixels), rendered using Mitsuba, along with
            associated data including <b>camera positions</b>, <b>depth</b>, <b>3D object models</b>, and <b>object
                masks</b>, are stored in the
            standard Blender format, with support for conversion to the COLMAP format, facilitating usability across the
            research community.
        </p>
        <p class="section-title">📌 Update log</p>

        <p class="section-title">🗓️ March 2025</p>
        <ul class="update-log">
            <li>Updated <b>denoise scripts</b> to identify and address rare missing cases caused by server-side cluster fluctuations.</li>
            <li>Refined benchmark results for selected algorithms (<i>NeRO</i>, <i>GES</i>, <i>GaussianShader</i>) on the <b>Ablation Dataset</b>.</li>
            <li>⚠️ Note: Main benchmark results remain <b>unaffected</b>.</li>
            <li>🔗 Updated results available at: <a href="https://christy61.github.io/openmaterial.github.io/" target="_blank">https://christy61.github.io/openmaterial.github.io/</a></li>
        </ul>

        <p class="section-title">🗓️ November 2024</p>
        <ul class="update-log">
            <li>Released <b>benchmark results</b> on the <b>Ablation Dataset</b>, with strict control over <b>shape</b>, <b>material</b>, and <b>lighting</b> variables.</li>
            <li>Benchmarked a set of representative algorithms across two tasks:
                <ul>
                    <li><i>Novel View Synthesis</i>: Gaussian Splatting, Instant-NGP, 2DGS, PGSR, GES, GSDR, GaussianShader</li>
                    <li><i>3D Reconstruction</i>: Instant-NeuS, NeuS2, 2DGS, PGSR, NeRO</li>
                </ul>
            </li>
            <li>Updated evaluation scripts to <b>incorporate new algorithms</b> and support the <b>Ablation Dataset benchmarking format</b>.</li>
            <li>Improved <b>evaluation code</b> to better visualize benchmarking comparisons.</li>
            <li>🔗 Full results available at: <a href="https://christy61.github.io/openmaterial.github.io/" target="_blank">https://christy61.github.io/openmaterial.github.io/</a></li>
        </ul>

        <p class="section-title">🗓️ October 2024</p>
        <ul class="update-log">
            <li>Released extended <b>benchmark results</b> on the <b>Main Dataset</b>:
                <ul>
                    <li><i>7 Novel View Synthesis methods</i>: Gaussian Splatting, Instant-NGP, 2DGS, PGSR, GES, GSDR, GaussianShader</li>
                    <li><i>6 3D Reconstruction methods</i>: Instant-NeuS, NeuS2, 2DGS, PGSR, NeRO, NeRRF</li>
                </ul>
            </li>
            <li>Highlighted algorithms specialized for <b>challenging materials</b>: NeRO, NeRRF, GSDR, GaussianShader.</li>
            <li>Updated evaluation scripts to <b>incorporate new algorithms</b>.</li>
        </ul>

        <p class="section-title">🗓️ September 2024</p>
        <ul class="update-log">
            <li>Introduced a new <b>Ablation Dataset</b> for controlled analysis of 3D reconstruction and view synthesis.</li>
            <li>Controlled variables:
                <ul>
                    <li><b>Objects</b>: Vase, Snail, Boat, Motor Bike, Statue</li>
                    <li><b>Lighting</b>: Indoor, Daytime Garden, Nighttime Street</li>
                    <li><b>Materials</b>: Conductor, Dielectric Plastic, Rough Conductor, Rough Dielectric, Rough Plastic, Diffuse</li>
                </ul>
            </li>
            <li>Total: <b>105 unique scenes</b> (5 × 3 × 7).</li>
            <li>🔗 Data is now available.</li>
        </ul>

        <p class="section-title">🗓️ July 2024</p>
        <ul class="update-log">
            <li>Dataset restructured for <b>flexible material-type-based downloading</b>.</li>
            <li>Users can now download subsets of data focusing on specific material categories (e.g., <i>diffuse</i>, <i>conductor</i>, <i>dielectric</i>, <i>plastic</i>).</li>
            <li>📦 Updated <b>download scripts</b> included.</li>
        </ul>

        <p class="section-title">Data structure</p>
        <p>
            The data structure of each subset is as follows:
        <pre>
            ├── name_of_object/[lighing_condition_name]-[material_type]-[material_name]
            │   ├── train
            │   │   ├── images
            │   │   │   ├── 000000.png
            │   │   │   |-- ...
            │   │   └── mask
            │   │   │   ├── 000000.png
            │   │   │   |-- ...
            │   │   └── depth
            │   │       ├── 000000.png
            │   │       |-- ...
            │   ├── test
            │   │   ├── images
            │   │   │   ├── 000000.png
            │   │   │   |-- ...
            │   │   └── mask
            │   │   │   ├── 000000.png
            │   │   │   |-- ...
            │   │   └── depth
            │   │       ├── 000000.png
            │   │       |-- ...
            │   └── transformas_train.json
            │   └── transformas_test.json
        </pre>
        </p>
        <!-- <p class="section-title">Citation</p>
        <p>
            If you find our work useful in your research, please cite:
        <pre>
        @article{Dang24,
            title={OpenMaterial: A Comprehensive Dataset of Complex Materials for 3D Reconstruction},
            author={Zheng Dang and Jialu Huang and Fei Wang and Mathieu Salzmann},
            journal={arXiv preprint arXiv:2406.08894},
            year={2024}
        }</pre>
        </p> -->
    </section>
</body>

</html>