<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>3D Shape Reconstruction</title>
    <style>
        html,
        body {
            margin-top: 10px;
            font-family: Arial, sans-serif;
            overflow: visible;
        }

        .section {
            width: 100%;
            height: fit-content;
            overflow: visible;
        }

        .section-title {
            font-size: 1.4em;
            margin-top: 15px;
            text-align: left;
            font-weight: bold;
        }

        .section-subtitle {
            font-size: 1.1em;
            margin-top: 5px;
            text-align: left;
            font-weight: bold;
        }

        .container-tex {
            width: 90%;
            margin: 10px auto;
            justify-content: center;
            text-align: left;
        }

        a {
            color: #1154a0;
            font-weight: normal;
            text-decoration: underline;
            line-height: 1.5;
        }

        pre {
            width: 85%;
            color: #555;
            margin: 8px auto;
            padding: 8px 10px;
            background: #eee;
            border: 1px solid #ddd;
            border-radius: 5px;
            overflow: auto;
            font-family: Consolas, "Courier New", monospace;
            font-size: 14px;
            line-height: 1.5;
        }

        a:visited {
            color: #1154a0;
        }

        a:hover {
            color: darkblue;
        }

        a:active {
            color: red;
        }

        p {
            width: 90%;
            margin: 10px auto;
            justify-content: center;
            text-align: left;
            line-height: 1.5;
        }

        ul.update-log {
            width: 87%;
            margin: 5px auto 15px;
            padding-left: 1.2em;
        }

        ul.update-log li {
            margin-bottom: 0.5em;
        }
    </style>
</head>

<body>
    <section class="section">
        <p class="section-title">Introduction</p>
        <p>
            Accurately reconstructing objects with complex optical properties, such as metals and glass, remains a
            formidable challenge due to their unique specular and light-transmission characteristics. To facilitate
            the
            development of solutions to these challenges, we introduce the OpenMaterial dataset, comprising 1001
            objects made of 295 distinct materialsâ€”including conductors, dielectrics, plastics, and their roughened
            variantsâ€”
            and captured under 723 diverse lighting conditions.
        </p>
        <img src="../images/teaser.png"
            style="width:60%; margin-left:auto; margin-right:auto; margin-top:20px; margin-bottom:5px; display:block">
        <p class="section-title">Overview</p>
        <p>
            Our dataset contains 1001 object centered scenes. To eliminate scale bias, we standardize object sizes
            within a unit sphere. This lets us sample camera
            positions using a Fibonacci grid on the upper hemisphere, ensuring uniform distribution and non-overlapping
            coverage. We then splits these camera positions into distinct training (50) and testing (40) viewpoints.
            All high-resolution images (1600x1200 pixels), rendered using Mitsuba, along with
            associated data including <b>camera positions</b>, <b>depth</b>, <b>3D object models</b>, and <b>object
                masks</b>, are stored in the
            standard Blender format, with support for conversion to the COLMAP format, facilitating usability across the
            research community.
        </p>
        <p class="section-title">ğŸ“Œ Update log</p>

        <p class="section-title">ğŸ—“ï¸ March 2025</p>
        <ul class="update-log">
            <li>Updated <b>denoise scripts</b> to identify and address rare missing cases caused by server-side cluster fluctuations.</li>
            <li>Refined benchmark results for selected algorithms (<i>NeRO</i>, <i>GES</i>, <i>GaussianShader</i>) on the <b>Ablation Dataset</b>.</li>
            <li>âš ï¸ Note: Main benchmark results remain <b>unaffected</b>.</li>
            <li>ğŸ”— Updated results available at: <a href="https://christy61.github.io/openmaterial.github.io/" target="_blank">https://christy61.github.io/openmaterial.github.io/</a></li>
        </ul>

        <p class="section-title">ğŸ—“ï¸ November 2024</p>
        <ul class="update-log">
            <li>Released <b>benchmark results</b> on the <b>Ablation Dataset</b>, with strict control over <b>shape</b>, <b>material</b>, and <b>lighting</b> variables.</li>
            <li>Benchmarked a set of representative algorithms across two tasks:
                <ul>
                    <li><i>Novel View Synthesis</i>: Gaussian Splatting, Instant-NGP, 2DGS, PGSR, GES, GSDR, GaussianShader</li>
                    <li><i>3D Reconstruction</i>: Instant-NeuS, NeuS2, 2DGS, PGSR, NeRO</li>
                </ul>
            </li>
            <li>Updated evaluation scripts to <b>incorporate new algorithms</b> and support the <b>Ablation Dataset benchmarking format</b>.</li>
            <li>Improved <b>evaluation code</b> to better visualize benchmarking comparisons.</li>
            <li>ğŸ”— Full results available at: <a href="https://christy61.github.io/openmaterial.github.io/" target="_blank">https://christy61.github.io/openmaterial.github.io/</a></li>
        </ul>

        <p class="section-title">ğŸ—“ï¸ October 2024</p>
        <ul class="update-log">
            <li>Released extended <b>benchmark results</b> on the <b>Main Dataset</b>:
                <ul>
                    <li><i>7 Novel View Synthesis methods</i>: Gaussian Splatting, Instant-NGP, 2DGS, PGSR, GES, GSDR, GaussianShader</li>
                    <li><i>6 3D Reconstruction methods</i>: Instant-NeuS, NeuS2, 2DGS, PGSR, NeRO, NeRRF</li>
                </ul>
            </li>
            <li>Highlighted algorithms specialized for <b>challenging materials</b>: NeRO, NeRRF, GSDR, GaussianShader.</li>
            <li>Updated evaluation scripts to <b>incorporate new algorithms</b>.</li>
        </ul>

        <p class="section-title">ğŸ—“ï¸ September 2024</p>
        <ul class="update-log">
            <li>Introduced a new <b>Ablation Dataset</b> for controlled analysis of 3D reconstruction and view synthesis.</li>
            <li>Controlled variables:
                <ul>
                    <li><b>Objects</b>: Vase, Snail, Boat, Motor Bike, Statue</li>
                    <li><b>Lighting</b>: Indoor, Daytime Garden, Nighttime Street</li>
                    <li><b>Materials</b>: Conductor, Dielectric Plastic, Rough Conductor, Rough Dielectric, Rough Plastic, Diffuse</li>
                </ul>
            </li>
            <li>Total: <b>105 unique scenes</b> (5 Ã— 3 Ã— 7).</li>
            <li>ğŸ”— Data is now available.</li>
        </ul>

        <p class="section-title">ğŸ—“ï¸ July 2024</p>
        <ul class="update-log">
            <li>Dataset restructured for <b>flexible material-type-based downloading</b>.</li>
            <li>Users can now download subsets of data focusing on specific material categories (e.g., <i>diffuse</i>, <i>conductor</i>, <i>dielectric</i>, <i>plastic</i>).</li>
            <li>ğŸ“¦ Updated <b>download scripts</b> included.</li>
        </ul>

        <p class="section-title">Data structure</p>
        <p>
            The data structure of each subset is as follows:
        <pre>
            â”œâ”€â”€ name_of_object/[lighing_condition_name]-[material_type]-[material_name]
            â”‚   â”œâ”€â”€ train
            â”‚   â”‚   â”œâ”€â”€ images
            â”‚   â”‚   â”‚   â”œâ”€â”€ 000000.png
            â”‚   â”‚   â”‚   |-- ...
            â”‚   â”‚   â””â”€â”€ mask
            â”‚   â”‚   â”‚   â”œâ”€â”€ 000000.png
            â”‚   â”‚   â”‚   |-- ...
            â”‚   â”‚   â””â”€â”€ depth
            â”‚   â”‚       â”œâ”€â”€ 000000.png
            â”‚   â”‚       |-- ...
            â”‚   â”œâ”€â”€ test
            â”‚   â”‚   â”œâ”€â”€ images
            â”‚   â”‚   â”‚   â”œâ”€â”€ 000000.png
            â”‚   â”‚   â”‚   |-- ...
            â”‚   â”‚   â””â”€â”€ mask
            â”‚   â”‚   â”‚   â”œâ”€â”€ 000000.png
            â”‚   â”‚   â”‚   |-- ...
            â”‚   â”‚   â””â”€â”€ depth
            â”‚   â”‚       â”œâ”€â”€ 000000.png
            â”‚   â”‚       |-- ...
            â”‚   â””â”€â”€ transformas_train.json
            â”‚   â””â”€â”€ transformas_test.json
        </pre>
        </p>
        <!-- <p class="section-title">Citation</p>
        <p>
            If you find our work useful in your research, please cite:
        <pre>
        @article{Dang24,
            title={OpenMaterial: A Comprehensive Dataset of Complex Materials for 3D Reconstruction},
            author={Zheng Dang and Jialu Huang and Fei Wang and Mathieu Salzmann},
            journal={arXiv preprint arXiv:2406.08894},
            year={2024}
        }</pre>
        </p> -->
    </section>
</body>

</html>